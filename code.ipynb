{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13335510,"sourceType":"datasetVersion","datasetId":8448598}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:41:33.795613Z","iopub.execute_input":"2025-10-12T16:41:33.795919Z","iopub.status.idle":"2025-10-12T16:41:33.800045Z","shell.execute_reply.started":"2025-10-12T16:41:33.795899Z","shell.execute_reply":"2025-10-12T16:41:33.799115Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-ml-challenge-ds/68e8d1d70b66d_student_resource/student_resource/dataset/train.csv')\ndf_t = pd.read_csv('/kaggle/input/amazon-ml-challenge-ds/68e8d1d70b66d_student_resource/student_resource/dataset/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:41:33.800881Z","iopub.execute_input":"2025-10-12T16:41:33.801105Z","iopub.status.idle":"2025-10-12T16:41:37.981129Z","shell.execute_reply.started":"2025-10-12T16:41:33.801084Z","shell.execute_reply":"2025-10-12T16:41:37.980514Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"pip install transformers torch pandas scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:41:37.984619Z","iopub.execute_input":"2025-10-12T16:41:37.984853Z","iopub.status.idle":"2025-10-12T16:42:54.798243Z","shell.execute_reply.started":"2025-10-12T16:41:37.984834Z","shell.execute_reply":"2025-10-12T16:42:54.797260Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.35.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- Preprocessing ---\n# Handle potential missing values in text (if any)\ndf['catalog_content'].fillna(\"missing\", inplace=True)\ndf_t['catalog_content'].fillna(\"missing\", inplace=True)\n\n# Log transform the target variable 'price'\n# np.log1p(x) is equivalent to np.log(x + 1), which handles prices of 0\ndf['price_log'] = np.log1p(df['price'])\n\nprint(\"Data loaded and preprocessed.\")\nprint(f\"Train data shape: {df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:43:01.394610Z","iopub.execute_input":"2025-10-12T16:43:01.395153Z","iopub.status.idle":"2025-10-12T16:43:01.516970Z","shell.execute_reply.started":"2025-10-12T16:43:01.395114Z","shell.execute_reply":"2025-10-12T16:43:01.516175Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Data loaded and preprocessed.\nTrain data shape: (75000, 5)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/1271518422.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['catalog_content'].fillna(\"missing\", inplace=True)\n/tmp/ipykernel_37/1271518422.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_t['catalog_content'].fillna(\"missing\", inplace=True)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer\nfrom torch.utils.data import Dataset, DataLoader\n\n# --- Configuration ---\nMODEL_NAME = 'bert-base-uncased' # A good starting point\nMAX_LEN = 128 # Max sequence length for BERT; adjust based on your text length\nBATCH_SIZE = 64\n\n# Initialize tokenizer\ntokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n\n# --- Create a custom PyTorch Dataset ---\nclass PricePredictionDataset(Dataset):\n    def __init__(self, texts, prices, tokenizer, max_len):\n        self.texts = texts\n        self.prices = prices\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        \n        # Tokenize the text\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        # Prepare item dictionary\n        item = {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n            'token_type_ids': inputs['token_type_ids'].flatten()\n        }\n        \n        # If prices are available (for training/validation)\n        if self.prices is not None:\n            item['targets'] = torch.tensor(self.prices[idx], dtype=torch.float)\n\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:43:13.331212Z","iopub.execute_input":"2025-10-12T16:43:13.331952Z","iopub.status.idle":"2025-10-12T16:43:23.919559Z","shell.execute_reply.started":"2025-10-12T16:43:13.331927Z","shell.execute_reply":"2025-10-12T16:43:23.918756Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b465e028d34edcbf7b004db9f92a87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaaa43a1b8204b5fbdb79c5cff3b752c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c68c998b88ea471681797ae11920db60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"552a3593862944039428939be5a87513"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\nfrom torch.optim import AdamW \n# Set device to GPU if available, else CPU\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# Load the model and configure it for regression (num_labels=1)\nmodel = BertForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=1 # This is the key for regression!\n)\n\n# Move the model to the selected device\nmodel.to(device)\n\nprint(f\"Model loaded on: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:43:31.083041Z","iopub.execute_input":"2025-10-12T16:43:31.083532Z","iopub.status.idle":"2025-10-12T16:43:47.391012Z","shell.execute_reply.started":"2025-10-12T16:43:31.083488Z","shell.execute_reply":"2025-10-12T16:43:47.390115Z"}},"outputs":[{"name":"stderr","text":"2025-10-12 16:43:33.772566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760287413.944308      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760287413.996104      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c149163cb294ef99c6823589b67b450"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded on: cuda\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\n\ndef smape(y_true, y_pred):\n    \"\"\"\n    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n    \n    Args:\n        y_true (np.array): Array of true values.\n        y_pred (np.array): Array of predicted values.\n        \n    Returns:\n        float: The SMAPE score.\n    \"\"\"\n    numerator = np.abs(y_pred - y_true)\n    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n    \n    # Handle the case where both y_true and y_pred are zero\n    # to avoid division by zero.\n    ratio = np.where(denominator == 0, 0, numerator / denominator)\n    \n    return np.mean(ratio) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:43:56.569728Z","iopub.execute_input":"2025-10-12T16:43:56.570287Z","iopub.status.idle":"2025-10-12T16:43:56.575177Z","shell.execute_reply.started":"2025-10-12T16:43:56.570262Z","shell.execute_reply":"2025-10-12T16:43:56.574297Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\n\n# Make sure device is set\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f\"Using device: {device}\")\n\n# Split data into training and validation sets\ntrain_texts, val_texts, train_prices, val_prices = train_test_split(\n    df['catalog_content'].values,\n    df['price_log'].values,\n    test_size=0.2,\n    random_state=55\n)\n\n# Create Dataset and DataLoader objects (as before)\ntrain_dataset = PricePredictionDataset(train_texts, train_prices, tokenizer, MAX_LEN)\nval_dataset = PricePredictionDataset(val_texts, val_prices, tokenizer, MAX_LEN)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Training Setup\nEPOCHS = 7\nLEARNING_RATE = 3e-5\nPATIENCE = 3  # Early stopping patience\n\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\nmodel.to(device)\n\nbest_val_loss = float('inf')\npatience_counter = 0\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_train_loss = 0\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['targets'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=targets)\n        loss = outputs.loss\n        total_train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n\n    avg_train_loss = total_train_loss / len(train_loader)\n\n    # Validation\n    model.eval()\n    total_val_loss = 0\n    val_preds_log = []\n    val_targets_log = []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=targets)\n            loss = outputs.loss\n            total_val_loss += loss.item()\n\n            val_preds_log.extend(outputs.logits.squeeze().cpu().numpy())\n            val_targets_log.extend(targets.cpu().numpy())\n\n    avg_val_loss = total_val_loss / len(val_loader)\n\n    # Convert predictions and targets back to original price scale\n    val_preds_orig = np.expm1(val_preds_log)\n    val_targets_orig = np.expm1(val_targets_log)\n\n    # Calculate validation SMAPE on original scale\n    val_smape = smape(val_targets_orig, val_preds_orig)\n\n    print(f\"Epoch {epoch + 1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val SMAPE: {val_smape:.4f}%\")\n\n    # Early stopping & save best model\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_counter = 0\n        torch.save(model.state_dict(), \"best_model.pth\")\n        print(\"Saved best model.\")\n    else:\n        patience_counter += 1\n        if patience_counter >= PATIENCE:\n            print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n            break\n\nprint(\"Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:45:56.552012Z","iopub.execute_input":"2025-10-12T16:45:56.552545Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch 1/7 | Train Loss: 0.6255 | Val Loss: 0.4605 | Val SMAPE: 51.4540%\nSaved best model.\nEpoch 2/7 | Train Loss: 0.4381 | Val Loss: 0.4291 | Val SMAPE: 49.0625%\nSaved best model.\nEpoch 3/7 | Train Loss: 0.3501 | Val Loss: 0.4274 | Val SMAPE: 47.8123%\nSaved best model.\nEpoch 4/7 | Train Loss: 0.2777 | Val Loss: 0.4217 | Val SMAPE: 46.9889%\nSaved best model.\nEpoch 5/7 | Train Loss: 0.2208 | Val Loss: 0.4595 | Val SMAPE: 48.5625%\nEpoch 6/7 | Train Loss: 0.1739 | Val Loss: 0.4410 | Val SMAPE: 47.2941%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Create test dataset and dataloader\ntest_texts = df_t['catalog_content'].values\n# Pass None for prices as they are not available for the test set\ntest_dataset = PricePredictionDataset(test_texts, None, tokenizer, MAX_LEN)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# --- Prediction Loop ---\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        predictions.extend(outputs.logits.squeeze().cpu().numpy())\n\n# Convert log predictions back to original price scale\nfinal_predictions = np.expm1(predictions)\n\n# Ensure prices are not negative (a safe-guard)\nfinal_predictions[final_predictions < 0] = 0 \n\n# Create submission file\nsubmission_df = pd.DataFrame({\n    'sample_id': df_t['sample_id'],\n    'price': final_predictions\n})\n\nsubmission_df.to_csv('test_out.csv', index=False)\nprint(\" Submission file created successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}